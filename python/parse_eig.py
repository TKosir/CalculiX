"""Utilities for parsing CalculiX frequency-step ``.eig`` files.

Overview of the binary layout
-----------------------------
CalculiX writes the frequency-domain restart file inside ``arpack.c``. The
records relevant for a real-valued (Hermitian) eigenproblem without cyclic
symmetry are emitted in the following order (each integer uses the internal
``ITG`` type and each float uses ``double`` precision)【F:src/arpack.c†L933-L996】【F:src/arpack.c†L1087-L1094】:

1. ``ITG`` cyclic-symmetry flag (``0`` for the standard case handled here).
2. ``ITG`` Hermitian indicator (``1`` for real-valued modes).
3. ``ITG`` perturbation flag ``iperturb[0]``.
4. Optional reference displacements ``vold`` written as ``mt * nk`` doubles if
   the perturbation flag equals ``1``.
5. ``ITG`` number of stored eigenpairs ``nev``.
6. ``nev`` ``double`` values containing the generalized eigenvalues
   :math:`\lambda = \omega^2`.
7. ``neq[1]`` ``double`` entries with the diagonal of the structural stiffness
   matrix ``[K]``.
8. ``nzs[2]`` ``double`` entries with the strictly lower-triangular values of
   ``[K]`` stored column-by-column using the solver structure generated by
   ``mastruct``【F:src/mastruct.c†L840-L908】.
9. ``neq[1]`` ``double`` entries with the diagonal of the consistent mass
   matrix ``[M]``.
10. ``nzs[1]`` ``double`` entries with the strictly lower-triangular values of
    ``[M]`` (same storage pattern as the stiffness matrix).
11. ``nev`` eigenvectors written as ``neq[1]`` consecutive doubles. The vectors
    are mass-normalised before being stored (``U^T M U = I`` in ``arpack.c``).

No degree-of-freedom mapping, sparse-structure pointers, or transformation
matrices are embedded in the restart file. The column structure (``jq`` / ``irow``)
resides in memory and is recomputed on restart by rerunning ``mastruct`` from
``.inp`` input data. Consequently, reconstructing sparse matrices from ``.eig``
values alone requires recovering the structural pattern from auxiliary files.
This module does so by combining the eigen restart file with the optional
``.dof`` map (active DOFs per node/component) and the original ``.inp`` deck.

API summary
-----------
``read_eig`` is the public entry point. It returns eigenvalues, frequencies,
eigenvectors, optional sparse mass/stiffness matrices (SciPy CSR), the optional
DOF map, optional transformation matrices (not present for the test case), and
compact metadata. Helper functions expose CLI validation against NumPy/SciPy
reference data, including MAC checks for the mode shapes.
"""

from __future__ import annotations

import argparse
import json
import math
import re
import struct
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple

import numpy as np
import scipy.sparse as sp

try:  # Optional dependency for Hungarian assignment
    from scipy.optimize import linear_sum_assignment  # type: ignore
except Exception:  # pragma: no cover - SciPy may be unavailable
    linear_sum_assignment = None  # type: ignore


@dataclass
class _FormatSpec:
    """Binary layout information inferred from the file header."""

    endian: str  # '<' or '>'
    int_size: int  # in bytes
    float_size: int  # in bytes (always 8 for CalculiX .eig files)

    @property
    def int_fmt(self) -> str:
        return self.endian + ("q" if self.int_size == 8 else "i")

    @property
    def float_fmt(self) -> str:
        return self.endian + "d"

    @property
    def float_dtype(self) -> np.dtype:
        return np.dtype(self.endian + "f8")


# Module-level overrides used by the CLI to provide auxiliary files.
_AUX_DOF_PATH: Optional[Path] = None
_AUX_INP_PATH: Optional[Path] = None


def configure_auxiliary_paths(*, dof: Optional[Path] = None, inp: Optional[Path] = None) -> None:
    """Update module-level overrides for locating auxiliary files."""

    global _AUX_DOF_PATH, _AUX_INP_PATH
    _AUX_DOF_PATH = Path(dof) if dof is not None else None
    _AUX_INP_PATH = Path(inp) if inp is not None else None


def _infer_precision_and_endianness(data: bytes) -> _FormatSpec:
    """Infer integer width and endianness from the leading records."""

    if len(data) < 24:
        raise ValueError("File too small to contain .eig header")

    candidates: List[_FormatSpec] = []
    head = memoryview(data)
    for int_size in (4, 8):
        if len(head) < int_size * 4:
            continue
        for endian in ("<", ">"):
            fmt_char = "q" if int_size == 8 else "i"
            try:
                flags = struct.unpack_from(endian + "3" + fmt_char, head, 0)
            except struct.error:
                continue
            cyclic, nherm, iperturb = flags
            if cyclic not in (0, 1):
                continue
            if nherm not in (0, 1):
                continue
            if iperturb not in (0, 1):
                continue
            candidates.append(_FormatSpec(endian, int_size, 8))

    if not candidates:
        raise ValueError("Unable to determine integer size/endianness from header")

    candidates.sort(key=lambda spec: (spec.endian != "<", spec.int_size))
    return candidates[0]


def _unpack_int(view: memoryview, offset: int, spec: _FormatSpec) -> Tuple[int, int]:
    value = struct.unpack_from(spec.int_fmt, view, offset)[0]
    return value, offset + spec.int_size


def _resolve_with_override(filepath: Path, suffix: str, override: Optional[Path]) -> Optional[Path]:
    if override is not None:
        return override
    candidate = filepath.with_suffix(suffix)
    if candidate.exists():
        return candidate
    return None


def _parse_header(view: memoryview, spec: _FormatSpec) -> Tuple[dict, int, Optional[np.ndarray]]:
    offset = 0
    cyclicsym, offset = _unpack_int(view, offset, spec)
    nherm, offset = _unpack_int(view, offset, spec)
    iperturb, offset = _unpack_int(view, offset, spec)

    meta = {
        "endianness": "little" if spec.endian == "<" else "big",
        "int_size": spec.int_size,
        "float_size": spec.float_size,
        "cyclic_symmetry": bool(cyclicsym),
        "hermitian": bool(nherm),
        "iperturb": int(iperturb),
    }

    if cyclicsym:
        raise NotImplementedError("Cyclic symmetry .eig files are not supported")
    if nherm != 1:
        raise NotImplementedError("Non-Hermitian eigenproblems are not supported")

    ref_displacements: Optional[np.ndarray] = None
    if iperturb not in (0, 1):
        raise ValueError(f"Unexpected iperturb flag {iperturb}")

    if iperturb == 1:
        # Reference displacements precede the eigenvalue block. Their length is
        # unknown a priori (mt*nk). We use the next integer after scanning
        # successive double counts.
        base = offset
        bytes_remaining = len(view) - base
        max_ref = max((bytes_remaining - spec.int_size) // spec.float_size, 0)
        for ref_count in range(max_ref + 1):
            pos = base + ref_count * spec.float_size
            if pos + spec.int_size > len(view):
                break
            candidate_nev = struct.unpack_from(spec.int_fmt, view, pos)[0]
            if candidate_nev <= 0 or candidate_nev > 10_000_000:
                continue
            ref_displacements = np.frombuffer(
                view, dtype=spec.float_dtype, offset=base, count=ref_count
            ).copy()
            meta["reference_displacements_count"] = int(ref_count)
            offset = pos
            break
        else:
            raise ValueError(
                "Unable to locate eigenvalue block after reference displacements"
            )

    return meta, offset, ref_displacements


def _infer_matrix_dimensions(
    remainder: np.ndarray,
    nev: int,
    ndof_hint: Optional[int],
) -> Tuple[int, int]:
    if ndof_hint is not None:
        remaining = remainder.size - ndof_hint * (nev + 2)
        if remaining < 0 or remaining % 2:
            raise ValueError("Degree-of-freedom count inconsistent with payload")
        return ndof_hint, remaining // 2

    for ndof in range(1, remainder.size + 1):
        remaining = remainder.size - ndof * (nev + 2)
        if remaining < 0:
            break
        if remaining % 2:
            continue
        offdiag = remaining // 2
        diag1 = remainder[:ndof]
        diag2 = remainder[ndof + offdiag : ndof + offdiag + ndof]
        if diag2.size < ndof:
            break
        if np.all(diag1 > 0) and np.all(diag2 > 0):
            return ndof, offdiag
    raise ValueError("Could not infer matrix dimensions from payload")


def _parse_body(
    data: bytes,
    offset: int,
    spec: _FormatSpec,
    nev: int,
    ndof_hint: Optional[int],
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, int]:
    floats = np.frombuffer(data, dtype=spec.float_dtype, offset=offset)
    if floats.size < nev:
        raise ValueError("File truncated before eigenvalue block")

    eigenvalues = np.array(floats[:nev], copy=True)
    remainder = floats[nev:]
    total = remainder.size
    if total == 0:
        raise ValueError("Missing stiffness/mass/eigenvector data")

    ndof, offdiag = _infer_matrix_dimensions(remainder, nev, ndof_hint)

    cursor = 0
    ad = np.array(remainder[cursor : cursor + ndof], copy=True)
    cursor += ndof
    au = np.array(remainder[cursor : cursor + offdiag], copy=True)
    cursor += offdiag
    adb = np.array(remainder[cursor : cursor + ndof], copy=True)
    cursor += ndof
    aub = np.array(remainder[cursor : cursor + offdiag], copy=True)
    cursor += offdiag

    eigenvector_count = ndof * nev
    if remainder.size < cursor + eigenvector_count:
        raise ValueError("Insufficient data for eigenvectors")
    eigvec_flat = remainder[cursor : cursor + eigenvector_count]
    eigenvectors = np.array(eigvec_flat, copy=True).reshape(nev, ndof).T

    return eigenvalues, eigenvectors, ad, au, adb, aub, ndof


def _element_node_count(element_type: str) -> int:
    match = re.search(r"(\d+)(?!.*\d)", element_type)
    if not match:
        raise ValueError(f"Cannot determine node count for element type '{element_type}'")
    return int(match.group(1))


def _read_dof_map(path: Path) -> np.ndarray:
    node_ids: List[int] = []
    comps: List[int] = []
    with path.open("r", encoding="utf-8") as handle:
        for line in handle:
            line = line.strip()
            if not line:
                continue
            node_str, comp_str = line.split(".")
            node_ids.append(int(node_str))
            comps.append(int(comp_str))
    eq_ids = np.arange(1, len(node_ids) + 1, dtype=np.int64)
    return np.column_stack((np.array(node_ids, dtype=np.int64), np.array(comps, dtype=np.int64), eq_ids))


def _structure_from_matrix_dump(base_path: Path, ndof: int) -> Optional[List[List[int]]]:
    """Reconstruct row-wise connectivity from CalculiX *.sti/*.mas dumps.

    The *.sti (stiffness) and *.mas (mass) files written during eigenvalue
    extraction contain the lower-triangular matrix entries as ``i j value``
    triples using one-based indexing【F:src/arpack.c†L962-L993】.  They are the
    authoritative definition of the sparsity pattern that is later replayed
    when reading the *.eig restart file in a subsequent step【F:src/steadystate.c†L357-L417】.
    Parsing these dumps is therefore more robust than attempting to infer the
    connectivity from the original *.inp deck, especially when MPCs,
    tie-constraints, or condensed DOFs alter the coupling pattern.

    Parameters
    ----------
    base_path:
        Path to the *.eig file (the function searches for sibling *.sti or
        *.mas files sharing the same stem).
    ndof:
        Number of active equations (length of the diagonal blocks written to
        the restart file).
    """

    for suffix in (".sti", ".mas"):
        candidate = base_path.with_suffix(suffix)
        if not candidate.exists():
            continue

        row_lists: List[List[int]] = [[] for _ in range(ndof)]
        with candidate.open("r", encoding="utf-8", errors="ignore") as handle:
            for line in handle:
                parts = line.strip().split()
                if len(parts) < 2:
                    continue
                try:
                    i = int(parts[0]) - 1
                    j = int(parts[1]) - 1
                except ValueError:
                    continue
                if not (0 <= i < ndof and 0 <= j < ndof):
                    continue
                if i == j:
                    continue
                if i > j:
                    i, j = j, i
                    if not (0 <= i < ndof and 0 <= j < ndof):
                        continue
                row_lists[i].append(j)

        return row_lists

    return None


def _structure_from_inp(dof_map: np.ndarray, inp_path: Path) -> List[List[int]]:
    eq_count = dof_map.shape[0]
    node_to_components: Dict[int, List[int]] = {}
    nodecomp_to_eq: Dict[Tuple[int, int], int] = {}
    for idx, (node, comp, _) in enumerate(dof_map):
        node_to_components.setdefault(int(node), []).append(int(comp))
        nodecomp_to_eq[(int(node), int(comp))] = idx

    adjacency: List[set[int]] = [set() for _ in range(eq_count)]
    lines = inp_path.read_text(encoding="utf-8", errors="ignore").splitlines()

    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if line.lower().startswith("*element"):
            args = [part.strip() for part in line.split(",") if part.strip()]
            elem_type = None
            for part in args:
                if part.lower().startswith("type="):
                    elem_type = part.split("=")[1].upper()
                    break
            if elem_type is None:
                raise ValueError(f"Element card missing type specification: {line}")
            node_count = _element_node_count(elem_type)
            i += 1
            buffer: List[str] = []
            while i < len(lines) and not lines[i].startswith("*"):
                buffer.extend([p.strip() for p in lines[i].split(",") if p.strip()])
                while len(buffer) >= node_count + 1:
                    nodes = list(map(int, buffer[1 : node_count + 1]))
                    eqs: List[int] = []
                    for node in nodes:
                        for comp in node_to_components.get(node, []):
                            eq = nodecomp_to_eq.get((node, comp))
                            if eq is not None:
                                eqs.append(eq)
                    if eqs:
                        eqs = sorted(set(eqs))
                        for idx_eq, col in enumerate(eqs):
                            for row in eqs[idx_eq + 1 :]:
                                adjacency[col].add(row)
                    buffer = buffer[node_count + 1 :]
                i += 1
            continue
        i += 1

    row_lists: List[List[int]] = [[] for _ in range(eq_count)]
    for col in range(eq_count):
        for row in adjacency[col]:
            lo, hi = (row, col) if row < col else (col, row)
            if lo == hi:
                continue
            row_lists[lo].append(hi)

    for lst in row_lists:
        lst.sort()

    return row_lists


def _assemble_symmetric(
    diag: np.ndarray,
    offdiag: np.ndarray,
    row_lists: List[List[int]],
) -> sp.csr_matrix:
    n = diag.size
    if len(row_lists) != n:
        raise ValueError("Row structure length mismatch")

    nnz_lower = sum(len(lst) for lst in row_lists)
    if offdiag.size != nnz_lower:
        raise ValueError(
            f"Off-diagonal length {offdiag.size} does not match structure ({nnz_lower})"
        )

    nnz = n + 2 * nnz_lower
    rows = np.empty(nnz, dtype=np.int64)
    cols = np.empty_like(rows)
    data = np.empty_like(rows, dtype=diag.dtype)

    cursor = 0
    k = 0
    for row in range(n):
        rows[cursor] = row
        cols[cursor] = row
        data[cursor] = diag[row]
        cursor += 1
        neighbors = row_lists[row]
        for col in neighbors:
            val = offdiag[k]
            rows[cursor] = row
            cols[cursor] = col
            data[cursor] = val
            cursor += 1
            rows[cursor] = col
            cols[cursor] = row
            data[cursor] = val
            cursor += 1
            k += 1

    matrix = sp.csr_matrix((data, (rows, cols)), shape=(n, n))
    return matrix


def read_eig(
    filepath: str,
    *,
    load_matrices: bool = False,
    load_mapping: bool = True,
    load_transforms: bool = True,
) -> Dict[str, object]:
    path = Path(filepath)
    data = path.read_bytes()
    spec = _infer_precision_and_endianness(data)
    view = memoryview(data)

    meta, offset, ref_displacements = _parse_header(view, spec)

    dof_path_candidate = _resolve_with_override(path, ".dof", _AUX_DOF_PATH)
    dof_map_internal: Optional[np.ndarray] = None
    if dof_path_candidate is not None and dof_path_candidate.exists():
        dof_map_internal = _read_dof_map(dof_path_candidate)

    nev, offset = _unpack_int(view, offset, spec)
    eigenvalues, eigenvectors, ad, au, adb, aub, ndof = _parse_body(
        data, offset, spec, nev, None if dof_map_internal is None else dof_map_internal.shape[0]
    )

    meta["n_dof"] = ndof
    meta["n_modes"] = int(nev)

    frequencies = np.sqrt(np.abs(eigenvalues)) / (2.0 * math.pi)

    dof_map: Optional[np.ndarray] = dof_map_internal if load_mapping else None
    meta["has_dof_map"] = dof_map is not None

    mass_matrix: Optional[sp.csr_matrix] = None
    stiffness_matrix: Optional[sp.csr_matrix] = None
    matrix_meta: Dict[str, dict] = {}

    if load_matrices:
        structure = _structure_from_matrix_dump(path, ndof)
        if structure is None:
            inp_path = _resolve_with_override(path, ".inp", _AUX_INP_PATH)
            if dof_map_internal is None or inp_path is None or not inp_path.exists():
                raise FileNotFoundError(
                    "Reconstructing sparse matrices requires .sti/.mas or both .dof and .inp files"
                )
            row_lists = _structure_from_inp(dof_map_internal, inp_path)
        else:
            row_lists = structure
        stiffness_matrix = _assemble_symmetric(ad, au, row_lists)
        mass_matrix = _assemble_symmetric(adb, aub, row_lists)
        matrix_meta = {
            "stiffness": {
                "shape": stiffness_matrix.shape,
                "nnz": int(stiffness_matrix.nnz),
                "symmetry": "symmetric",
                "storage": "lower",
            },
            "mass": {
                "shape": mass_matrix.shape,
                "nnz": int(mass_matrix.nnz),
                "symmetry": "symmetric",
                "storage": "lower",
            },
        }
    meta["matrix_meta"] = matrix_meta

    transforms: Optional[Dict[str, sp.spmatrix]] = None
    if load_transforms:
        transforms = {}
    meta["has_transforms"] = bool(transforms)

    if ref_displacements is not None:
        meta["reference_displacements"] = ref_displacements

    result: Dict[str, object] = {
        "eigenvalues": eigenvalues,
        "frequencies_hz": frequencies,
        "eigenvectors": eigenvectors,
        "mass": mass_matrix,
        "stiffness": stiffness_matrix,
        "dof_map": dof_map,
        "transforms": transforms,
        "meta": meta,
    }
    return result


def _relative_error(measured: np.ndarray, reference: np.ndarray) -> np.ndarray:
    denom = np.where(np.abs(reference) > 0, np.abs(reference), 1.0)
    return np.abs(measured - reference) / denom


def _mac_matrix(a: np.ndarray, b: np.ndarray) -> np.ndarray:
    a_c = np.asarray(a, dtype=np.complex128)
    b_c = np.asarray(b, dtype=np.complex128)
    num = np.abs(a_c.conj().T @ b_c) ** 2
    den = np.outer(np.sum(np.abs(a_c) ** 2, axis=0), np.sum(np.abs(b_c) ** 2, axis=0))
    with np.errstate(divide="ignore", invalid="ignore"):
        mac = np.divide(num, den, out=np.zeros_like(num, dtype=np.float64), where=den != 0)
    return mac


def _format_stats(values: np.ndarray) -> str:
    return f"min={values.min():.3e}, mean={values.mean():.3e}, max={values.max():.3e}"


def _orthonormal_basis(vectors: np.ndarray) -> np.ndarray:
    if vectors.size == 0:
        return vectors
    q, _ = np.linalg.qr(vectors, mode="reduced")
    return q


def _compare_sparse_matrices(
    parsed: sp.csr_matrix,
    reference: sp.csr_matrix,
    *,
    rtol: float,
    atol: float,
) -> Dict[str, object]:
    if parsed.shape != reference.shape:
        raise ValueError("Matrix shape mismatch with reference")

    diff = (parsed - reference).tocoo()
    ref_norm = math.sqrt(float((reference.data ** 2).sum()))
    diff_norm = math.sqrt(float((diff.data ** 2).sum()))
    rel = diff_norm / max(1.0, ref_norm)
    passed = diff_norm <= max(atol, rtol * max(1.0, ref_norm))

    symmetry_diff = (parsed - parsed.T).tocoo()
    symmetry_norm = math.sqrt(float((symmetry_diff.data ** 2).sum()))

    return {
        "fro_norm": diff_norm,
        "fro_rel": rel,
        "symmetry_norm": symmetry_norm,
        "pass": bool(passed),
    }


def _validate_dof_map(parsed: np.ndarray, reference: np.ndarray) -> Dict[str, object]:
    if parsed.shape != reference.shape:
        raise ValueError("DOF map length mismatch")
    mismatches = np.where((parsed[:, :2] != reference[:, :2]).any(axis=1))[0]
    return {
        "pass": mismatches.size == 0,
        "mismatch_count": int(mismatches.size),
        "first_mismatch": int(mismatches[0]) if mismatches.size else None,
    }


def _validate_against_reference(
    result: Dict[str, object],
    ref_dir: Path,
    *,
    rtol: float,
    atol: float,
    mac_threshold: float,
    use_assignment: bool,
    rigid_threshold: float,
    rtol_mat: float,
    atol_mat: float,
    dof_reference: Optional[np.ndarray],
) -> Dict[str, object]:
    eigenvalues = result["eigenvalues"]
    frequencies = result["frequencies_hz"]
    eigenvectors = result["eigenvectors"]

    ref_eigenvalues = np.load(ref_dir / "eigenvalues.npy")
    ref_frequencies = np.load(ref_dir / "frequencies.npy")
    ref_eigenvectors = np.load(ref_dir / "eigenvectors.npy")

    if eigenvalues.shape != ref_eigenvalues.shape:
        raise ValueError("Eigenvalue count mismatch with reference")
    if frequencies.shape != ref_frequencies.shape:
        raise ValueError("Frequency count mismatch with reference")
    if eigenvectors.shape != ref_eigenvectors.shape:
        raise ValueError("Eigenvector shape mismatch with reference")

    rigid_mask = (np.abs(frequencies) < rigid_threshold) & (np.abs(ref_frequencies) < rigid_threshold)
    flex_mask = ~rigid_mask

    validation: Dict[str, object] = {
        "rigid_mask": rigid_mask,
        "flex_mask": flex_mask,
    }

    eig_pass = True
    freq_pass = True

    if np.any(flex_mask):
        eig_rel = _relative_error(eigenvalues[flex_mask], ref_eigenvalues[flex_mask])
        freq_rel = _relative_error(frequencies[flex_mask], ref_frequencies[flex_mask])
        eig_pass = np.allclose(eigenvalues[flex_mask], ref_eigenvalues[flex_mask], rtol=rtol, atol=atol)
        freq_pass = np.allclose(frequencies[flex_mask], ref_frequencies[flex_mask], rtol=rtol, atol=atol)

        print("Eigenvalue relative errors (flexible modes):")
        for idx, err in zip(np.nonzero(flex_mask)[0], eig_rel):
            print(f"  mode {idx+1:3d}: {err:.3e}")
        print(f"Eigenvalue error summary: {_format_stats(eig_rel)}; pass={eig_pass}")

        print("Frequency relative errors (flexible modes):")
        for idx, err in zip(np.nonzero(flex_mask)[0], freq_rel):
            print(f"  mode {idx+1:3d}: {err:.3e}")
        print(f"Frequency error summary: {_format_stats(freq_rel)}; pass={freq_pass}")
    else:
        print("No flexible modes for eigenvalue/frequency comparison.")

    mac_pass = True
    mac_diag = np.array([])
    permutation = np.arange(eigenvalues.size)
    if np.any(flex_mask):
        mac = _mac_matrix(eigenvectors[:, flex_mask], ref_eigenvectors[:, flex_mask])
        if use_assignment:
            if linear_sum_assignment is None:
                raise RuntimeError("scipy is required for --use-assignment but is not available")
            cost = -mac
            row_ind, col_ind = linear_sum_assignment(cost)
            mac_diag = mac[row_ind, col_ind]
            flex_indices = np.nonzero(flex_mask)[0]
            permutation = flex_indices[col_ind]
            print("Applied mode pairing via Hungarian assignment (flexible modes):")
            print("  mapping parsed mode -> reference mode:", permutation + 1)
        else:
            mac_diag = np.diag(mac)
            permutation = np.nonzero(flex_mask)[0]
        mac_pass = bool(np.all(mac_diag >= mac_threshold))
        print("MAC diagonal values (flexible modes):")
        for idx, val in zip(permutation, mac_diag):
            print(f"  mode {idx+1:3d}: {val:.6f}")
        print(f"MAC summary: {_format_stats(mac_diag)}; pass={mac_pass}")
    else:
        print("No flexible modes available for MAC evaluation.")

    rigid_subspace_pass = True
    rigid_subspace_values = np.array([])
    if np.any(rigid_mask):
        basis_a = _orthonormal_basis(eigenvectors[:, rigid_mask])
        basis_b = _orthonormal_basis(ref_eigenvectors[:, rigid_mask])
        if basis_a.size and basis_b.size:
            singular_vals = np.linalg.svd(basis_a.T @ basis_b, compute_uv=False)
            rigid_subspace_values = singular_vals**2
            rigid_subspace_pass = bool(np.min(rigid_subspace_values) >= mac_threshold)
            print("Rigid-body subspace MAC (principal angles squared):", rigid_subspace_values)
            print(f"Rigid-body subspace pass={rigid_subspace_pass}")
        else:
            print("Rigid-body subspace insufficient to compute MAC (degenerate vectors).")

    overall_mac_pass = mac_pass and rigid_subspace_pass

    validation.update(
        {
            "eig_pass": bool(eig_pass),
            "freq_pass": bool(freq_pass),
            "mac_pass": overall_mac_pass,
            "mac_diag": mac_diag,
            "mac_permutation": permutation,
            "rigid_subspace_mac": rigid_subspace_values,
            "rigid_pass": rigid_subspace_pass,
        }
    )

    stiffness_validation = None
    mass_validation = None
    if (ref_dir / "stiffness_matrix.npz").exists() and result.get("stiffness") is not None:
        stiffness_validation = _compare_sparse_matrices(
            result["stiffness"], sp.load_npz(ref_dir / "stiffness_matrix.npz"), rtol=rtol_mat, atol=atol_mat
        )
        print(
            "Stiffness matrix Frobenius error: {fro_norm:.3e} (rel {fro_rel:.3e}); symmetry {symmetry_norm:.3e}; pass={pass}".format(
                **stiffness_validation
            )
        )
    if (ref_dir / "mass_matrix.npz").exists() and result.get("mass") is not None:
        mass_validation = _compare_sparse_matrices(
            result["mass"], sp.load_npz(ref_dir / "mass_matrix.npz"), rtol=rtol_mat, atol=atol_mat
        )
        print(
            "Mass matrix Frobenius error: {fro_norm:.3e} (rel {fro_rel:.3e}); symmetry {symmetry_norm:.3e}; pass={pass}".format(
                **mass_validation
            )
        )

    if dof_reference is not None and result.get("dof_map") is not None:
        dof_validation = _validate_dof_map(result["dof_map"], dof_reference)
        print(
            "DOF mapping comparison: pass={pass}, mismatches={mismatch_count}".format(
                **dof_validation
            )
        )
        validation["dof_validation"] = dof_validation

    validation["stiffness_validation"] = stiffness_validation
    validation["mass_validation"] = mass_validation
    return validation


def _write_report(report_path: Path, result: Dict[str, object], validation: Optional[dict]) -> None:
    output = {
        "dofs": int(result["meta"].get("n_dof", result["eigenvectors"].shape[0])),
        "modes": int(result["eigenvectors"].shape[1]),
    }
    if validation is not None:
        mac_diag = validation.get("mac_diag", np.array([]))
        output.update(
            {
                "eigenvalues_pass": validation["eig_pass"],
                "frequencies_pass": validation["freq_pass"],
                "mac_pass": validation["mac_pass"],
                "mac_threshold": float(np.min(mac_diag)) if mac_diag.size else None,
                "mac_diag": mac_diag.tolist(),
                "rigid_subspace_mac": validation.get("rigid_subspace_mac", np.array([])).tolist(),
            }
        )
        if validation.get("stiffness_validation"):
            output["stiffness_validation"] = validation["stiffness_validation"]
        if validation.get("mass_validation"):
            output["mass_validation"] = validation["mass_validation"]
        if validation.get("dof_validation"):
            output["dof_validation"] = validation["dof_validation"]
    report_path.write_text(json.dumps(output, indent=2), encoding="utf-8")
    print(f"Wrote validation report to {report_path}")


def main(argv: Optional[Iterable[str]] = None) -> None:
    parser = argparse.ArgumentParser(description="Parse CalculiX .eig files and validate against references.")
    parser.add_argument("--eig", required=True, help="Path to the .eig file")
    parser.add_argument("--ref-dir", help="Directory containing reference NumPy/SciPy arrays")
    parser.add_argument("--rtol", type=float, default=1e-6, help="Relative tolerance for eigenvalue/frequency comparisons")
    parser.add_argument("--atol", type=float, default=1e-12, help="Absolute tolerance for eigenvalue/frequency comparisons")
    parser.add_argument("--mac-threshold", type=float, default=0.99, help="Minimum acceptable MAC value")
    parser.add_argument("--use-assignment", action="store_true", help="Use Hungarian assignment to pair modes before MAC reporting")
    parser.add_argument("--write-report", action="store_true", help="Emit a JSON summary next to the .eig file")
    parser.add_argument("--rigid-threshold", type=float, default=1.0, help="Frequency threshold (Hz) below which modes are treated as rigid")
    parser.add_argument("--load-matrices", action="store_true", help="Reconstruct and validate mass/stiffness matrices")
    parser.add_argument("--load-mapping", action="store_true", help="Load DOF mapping")
    parser.add_argument("--load-transforms", action="store_true", help="Parse optional transformation matrices")
    parser.add_argument("--rtol-mat", type=float, default=1e-8, help="Relative tolerance for matrix comparison")
    parser.add_argument("--atol-mat", type=float, default=1e-12, help="Absolute tolerance for matrix comparison")
    parser.add_argument("--dof-file", help="Path to the .dof mapping file")
    parser.add_argument("--inp-file", help="Path to the .inp deck for matrix reconstruction")

    args = parser.parse_args(list(argv) if argv is not None else None)

    configure_auxiliary_paths(
        dof=Path(args.dof_file) if args.dof_file else None,
        inp=Path(args.inp_file) if args.inp_file else None,
    )

    result = read_eig(
        args.eig,
        load_matrices=args.load_matrices,
        load_mapping=args.load_mapping or bool(args.dof_file),
        load_transforms=args.load_transforms,
    )

    ndof = result["eigenvectors"].shape[0]
    nev = result["eigenvectors"].shape[1]
    print(f"Parsed {ndof} DOFs and {nev} modes from {args.eig}")
    print(f"Endianness: {result['meta']['endianness']}, int size: {result['meta']['int_size']} bytes")

    validation = None
    dof_reference = None
    if args.dof_file:
        dof_reference = _read_dof_map(Path(args.dof_file))

    if args.ref_dir:
        ref_dir = Path(args.ref_dir)
        validation = _validate_against_reference(
            result,
            ref_dir,
            rtol=args.rtol,
            atol=args.atol,
            mac_threshold=args.mac_threshold,
            use_assignment=args.use_assignment,
            rigid_threshold=args.rigid_threshold,
            rtol_mat=args.rtol_mat,
            atol_mat=args.atol_mat,
            dof_reference=dof_reference,
        )
        mac_pass = validation["mac_pass"]
        eig_pass = validation["eig_pass"]
        freq_pass = validation["freq_pass"]
        if eig_pass and freq_pass and mac_pass:
            print("All validation checks passed.")
        else:
            print(
                "Validation failed: eigenvalues pass=%s, frequencies pass=%s, MAC pass=%s"
                % (eig_pass, freq_pass, mac_pass)
            )

    if args.write_report:
        eig_path = Path(args.eig)
        report_path = eig_path.with_name(eig_path.name + "_validation.json")
        _write_report(report_path, result, validation)


if __name__ == "__main__":
    main()
